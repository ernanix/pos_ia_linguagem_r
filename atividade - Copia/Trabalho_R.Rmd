
<style>
  body {
    text-align: justify
  }
</style>

![](top.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r,echo=FALSE}
  #setwd("C:/Users/escneto/Documents/Estudos/Pos_IA_UFPR/Linguagem_Programacao_R/atividade")
  setwd("D:/Cursos/Pos_IA/linguagem_r/atividade")
```


#### **TRABALHO DA DISCIPLINA - LINGUAGEM R**
#### **Aluno:**Ernani de Souza Cubas Neto 

***

#### **Pesquisa com Dados de Satélite (Satellite)**

##### O banco de dados consiste nos valores multi-espectrais de pixels em vizinhanças 3x3 em uma imagem de satélite, e na classificação associada ao pixel central em cada vizinhança. O objetivo é prever esta classificação, dados os valores multi-espectrais.

##### Um quadro de imagens do Satélite Landsat com MSS (Multispectral Scanner System) consiste em quatro imagens digitais da mesma cena em diferentes bandas espectrais. Duas delas estão na região visível (correspondendo aproximadamente às regiões verde e vermelha do espectro visível) e duas no infravermelho (próximo). Cada pixel é uma palavra binária de 8 bits, com 0 correspondendo a preto e 255 a branco. A resolução espacial de um pixel é de cerca de 80m x 80m. Cada imagem contém 2340 x 3380 desses pixels. O banco de dados é uma subárea (minúscula) de uma cena, consistindo de 82 x 100 pixels. Cada linha de dados corresponde a uma vizinhança quadrada de pixels 3x3 completamente contida dentro da subárea 82x100. Cada linha contém os valores de pixel nas quatro bandas espectrais (convertidas em ASCII) de cada um dos 9 pixels na vizinhança de 3x3 e um número indicando o rótulo de classificação do pixel central.

##### As classes são: solo vermelho, colheita de algodão, solo cinza, solo cinza úmido, restolho de vegetação, solo cinza muito úmido.

##### Os dados estão em ordem aleatória e certas linhas de dados foram removidas, portanto você não pode reconstruir a imagem original desse conjunto de dados. Em cada linha de dados, os quatro valores espectrais para o pixel superior esquerdo são dados primeiro, seguidos pelos quatro valores espectrais para o pixel superior central e, em seguida, para o pixel superior direito, e assim por diante, com os pixels lidos em sequência, da esquerda para a direita e de cima para baixo. Assim, os quatro valores espectrais para o pixel central são dados pelos atributos 17, 18, 19 e 20. Se você quiser, pode usar apenas esses quatro atributos, ignorando os outros. Isso evita o problema que surge quando uma vizinhança 3x3 atravessa um limite.

##### O banco de dados se encontra no pacote **mlbench** e é completo (não possui dados faltantes)

> #### **Carregando a base:**

```{r,echo=TRUE}
  library("mlbench")
  data(Satellite)
  dados_satelite <- Satellite
```
> #### **Particionando a base:**

```{r,echo=TRUE}
  library(caret)
  set.seed(2114)
  indices <- createDataPartition(dados_satelite$classes, p=0.80, list=FALSE)
  treino <- dados_satelite[indices,]
  teste <- dados_satelite[-indices,]
```
***
> #### **Tarefas:**
> #### 1. Treine modelos RandomForest, SVM e RNA para predição destes dados.

```{r,echo=TRUE}
  rf <- caret::train(classes~x.17+x.18+x.19+x.20, data=treino, method="rf")
  svm <- caret::train(classes~x.17+x.18+x.19+x.20, data=treino, method="svmRadial")
  rna <- caret::train(classes~x.17+x.18+x.19+x.20, data=treino, method="nnet",trace=FALSE)
  
```
***
> #### 2. Escolha o melhor modelo com base em suas matrizes de confusão.
> #### 2.1. Aplicar modelos treinados na base de Teste

```{r,echo=TRUE}
  predict.rf <- predict(rf, teste)
  predict.svm <- predict(svm, teste)
  predict.rna <- predict(rna, teste)
```
> #### 2.2. Criar as matrizes de confusão e comparar os resultados

```{r,echo=TRUE}
  confusionMatrix(predict.rf, teste$classes)
  confusionMatrix(predict.svm, teste$classes)
  confusionMatrix(predict.rna, teste$classes)
```
***
> #### 3. Treine o modelo final com todos os dados e faça a predição na base completa.
> #### 3.1. Verificando o valor de sigma e C

```{r,echo=TRUE}
  print(svm)
```
> #### 3.2. Treinando o modelo final com os dados encontrados

```{r,echo=TRUE}
  library(kernlab)
  final_model <- ksvm(type="C-svc", classes~x.17+x.18+x.19+x.20, data=dados_satelite, kernel="rbfdot",
                      C=1.0, kpar=list(sigma=1.033562))
  final_predict.svm <- predict(final_model, dados_satelite)
  confusionMatrix(final_predict.svm, dados_satelite$classes)
```
***
> #### 4. Analise o resultado.
> #### *Dentre os três modelos testados (RandomForest, SVM e RNA), o SVM foi o que apresentou maior acurácia no teste da Matriz de Confusão, com valor de 0,8629.*
> #### *Para criação do modelo final, foram levantados e usados os valores de Sigma e C, resultando em uma acurácia no teste da Matriz de Confusão usando todos os dados em 0,8693* 

***
> #### 5. Salve este modelo final

```{r,echo=TRUE}
  saveRDS(final_model, "satellite_svm.rds")
```

***

#### **Estimativa de Volumes de Árvores**

##### Modelos de aprendizado de máquina são bastante usados na área da engenharia florestal (mensuração florestal) para, por exemplo, estimar o volume de madeira de árvores sem ser necessário abatê-las.

##### O processo é feito pela coleta de dados (dados observados) através do abate de algumas árvores, onde sua altura, diâmetro na altura do peito (dap), etc, são medidos de forma exata. Com estes dados, treina-se um modelo de AM que pode estimar o volume de outras árvores da população.

##### As classes são: solo vermelho, colheita de algodão, solo cinza, solo cinza úmido, restolho de vegetação, solo cinza muito úmido.

##### Os modelos, chamados **alométricos**, são usados na área há muitos anos e são baseados em regressão (linear ou não) para encontrar uma equação que descreve os dados. Por exemplo, o modelo de Spurr é dado por:

> ##### Volume = b0 + b1 * dap² * Ht

##### Onde **dap** é o diâmetro na altura do peito (1,3metros), **Ht** é a altura total. Tem-se vários modelos alométricos, cada um com uma determinada característica, parâmetros, etc. Um modelo de regressão envolve aplicar os dados observados e encontrar b0 e b1 no modelo apresentado, gerando assim uma equação que pode ser usada para prever o volume de outras árvores.

##### Dado o arquivo **Volumes.csv**, que contém os dados de observação, escolha um modelo de aprendizado de máquina com a melhor estimativa, a partir da estatística de correlação.

> #### **Tarefas:**
> #### 1. Carregar o arquivo **Volumes.csv**

```{r,echo=TRUE}
    df_vol <-read.csv("Volumes.csv",sep=";",dec=",")
```
***
> #### 2. Eliminar a coluna NR, que só apresenta um número sequencial

```{r,echo=TRUE}
    df_vol$NR <- NULL
```
***
> #### 3. Criar partição de dados: treinamento 80%, teste 20%

```{r,echo=TRUE}
    indices <- createDataPartition(df_vol$VOL, p=0.80,
                               list=FALSE)
    treino <- df_vol[indices,]
    teste <- df_vol[-indices,]
```
***
> #### 4. Usando o pacote "caret", treinar os modelos: Random Forest (rf), SVM (svmRadial), Redes Neurais (neuralnet) e o modelo alométrico de SPURR
> #### 5. O modelo alométrico é dado por: Volume = b0 + b1 * dap2 * Ht

```{r,echo=TRUE,warning=FALSE}
  rf <- caret::train(VOL~., data=treino, method="rf")
  svm <- caret::train(VOL~., data=treino, method="svmRadial")
  rna <- caret::train(VOL~., data=treino, method="neuralnet")
  alom <- nls(VOL ~ b0 + b1*DAP*DAP*HT, treino, start=list(b0=0.5,b1=0.5))
```
***
> #### 6.Efetue as predições nos dados de teste

```{r,echo=TRUE}
  predict.rf <- predict(rf, teste)
  predict.svm <- predict(svm, teste)
  predict.rna <- predict(rna, teste)
  predict.alom <- predict(alom, teste)
```
***
> #### 7.Crie funções e calcule as seguintes métricas entre a predição e os dados observados
> #### 7.1 Coeficiente de Determinação - R²

```{r,echo=TRUE}
  coef_determinacao <- function(val_obs,val_pred,med_obs){
     sum1 <- sum((val_obs - val_pred) ^ 2)
     sum2 <- sum((val_obs - med_obs) ^ 2)
     return (1-(sum1 / sum2))
  }
```
> #### 7.2 Erro padrão da estimativa: S~yx~

```{r,echo=TRUE}
  erro_padrao <- function(val_obs,val_pred) {
     sum1 <- sum((val_obs - val_pred) ^ 2)
     count <- length(teste$VOL)
     return (sqrt(sum1 / (count-2)))
  }
```
> #### 7.3 S~yx~ %

```{r,echo=TRUE}
  erro_padrao_porc <- function(val_obs,val_pred,med_obs) {
     erro_padrao <- erro_padrao(val_obs,val_pred)
     return ((erro_padrao / med_obs) * 100)
  }
```

> #### 7.4 Calculando o R²

```{r,echo=TRUE}
  print(paste("RandomForest:",coef_determinacao(teste$VOL,predict.rf,mean(teste$VOL))))
  print(paste("SVM:",coef_determinacao(teste$VOL,predict.svm,mean(teste$VOL))))
  print(paste("Redes Neurais:",coef_determinacao(teste$VOL,predict.rna,mean(teste$VOL))))
  print(paste("Modelo Alométrico:",coef_determinacao(teste$VOL,predict.alom,mean(teste$VOL))))
```

> #### 7.4 Calculando o S~yx~

```{r,echo=TRUE}
  print(paste("RandomForest:",erro_padrao(teste$VOL,predict.rf)))
  print(paste("SVM:",erro_padrao(teste$VOL,predict.svm)))
  print(paste("Redes Neurais:",erro_padrao(teste$VOL,predict.rna)))
  print(paste("Modelo Alométrico:",erro_padrao(teste$VOL,predict.alom)))
```

> #### 7.4 Calculando o S~yx~%

```{r,echo=TRUE}
  print(paste("RandomForest:",erro_padrao_porc(teste$VOL,predict.rf,mean(teste$VOL))))
  print(paste("SVM:",erro_padrao_porc(teste$VOL,predict.svm,mean(teste$VOL))))
  print(paste("Redes Neurais:",erro_padrao_porc(teste$VOL,predict.rna,mean(teste$VOL))))
  print(paste("Modelo Alométrico:",erro_padrao_porc(teste$VOL,predict.alom,mean(teste$VOL))))
```
***
> #### 8. Escolha o melhor modelo
> #### *No cálculo do Coeficiente de Determinação, o modelo **Alométrico** obteve melhor desempenho, com valor 0.8447, ou seja, mais próximo de 1*
> #### *Pelo cálculo do erro padrão da estimativa e sua porcentagem, os valores reafirmam que o modelo **Alométrico** é o que realmente possui melhores resultados, apresentando a menor porcentagem de erro, de 12.25% * 